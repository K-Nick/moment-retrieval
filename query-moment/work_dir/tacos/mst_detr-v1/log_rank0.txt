[2022-12-20 15:25:00](root:57)INFO []
[2022-12-20 15:25:00](root:59)INFO {'paths': {'root_dir': '/export/home2/kningtg/WORKSPACE/moment-retrieval/query-moment', 'data_dir': '/export/home2/kningtg/WORKSPACE/moment-retrieval/data-bin/raw', 'cache_dir': '/export/home2/kningtg/WORKSPACE/moment-retrieval/data-bin/cache', 'work_dir': '${paths.root_dir}/work_dir/${data.dataset}/${flags.exp}'}, 'flags': {'debug': False, 'ddp': False, 'amp': False, 'train': True, 'wandb': False, 'seed': 3147, 'exp': 'mst_detr-v1'}, 'data': {'datapipe': 'mst_detr', 'dataset': 'tacos', 'dataset_dir': '${paths.data_dir}/${data.dataset}', 'max_len_video': 512, 'target_stride': 4, 'word_mask_rate': 0.15, 'vid_hdf5': 'i3d.hdf5', 'vid_hdf5_key_template': '{video_id}'}, 'eval': {'ms': [1, 5], 'ns': [0.3, 0.5, 0.7], 'best_monitor': 'R1@IoU=0.7', 'is_best': 'max'}, 'train': {'num_workers': 8, 'num_epochs': 100, 'eval_epoch_interval': 1, 'batch_size': 32, 'optimizer': {'params': None, 'lr': 0.0001, 'betas': [0.9, 0.999], 'weight_decay': 0.0001, '_target_': <class 'torch.optim.adamw.AdamW'>}, 'clip_grad': 10.0, 'lr_scheduler': {'optimizer': None, 'factor': 0.5, 'patience': 5, 'verbose': True, '_target_': <class 'torch.optim.lr_scheduler.ReduceLROnPlateau'>}, 'val_interval': 1.0, 'print_interval': 0.2}, 'model_cfg': {'d_model': 512, 'ff_dim': 512, 'nhead': 16, 'num_layers_enc': 4, 'num_layers_dec': 3, 'sr_ratio_lvls': [4, 4, 2, 1], 'use_patch_merge': [True, False, True, True], 'dropout': 0.1, 'w_iou_loss': 30.0, 'w_l1_loss': 10.0, 'w_mask_loss': 0.5, 'w_enc_aux_loss': 1.0, 'w_dec_aux_loss': 1.0, 'focal_alpha': 0.1, 'sigma_s': 0.21, 'sigma_m': 0.25, 'topk': 1}, 'model': {'backbone': {'backbone': {'d_model_in': '${model_cfg.d_model}', 'd_model_lvls': {'s': '[${model_cfg.d_model}] * ${model_cfg.num_layers_enc}', '_target_': <function eval_str_impl at 0x155446d3a0e0>}, 'num_head_lvls': {'s': '[${model_cfg.nhead}] * ${model_cfg.num_layers_enc}', '_target_': <function eval_str_impl at 0x155446d3a0e0>}, 'ff_dim_lvls': {'s': '[${model_cfg.d_model}] * ${model_cfg.num_layers_enc}', '_target_': <function eval_str_impl at 0x155446d3a0e0>}, 'input_vid_dim': 1024, 'input_txt_dim': 300, 'max_vid_len': 512, 'max_txt_len': 100, 'sr_ratio_lvls': '${model_cfg.sr_ratio_lvls}', 'use_patch_merge': '${model_cfg.use_patch_merge}', '_target_': <class 'models.backbone.segformerx.SegFormerX'>}, 'output_layer': [0, 2, 3], 'intermediate_hidden_size': ['${model_cfg.d_model}', '${model_cfg.d_model}', '${model_cfg.d_model}'], 'fpn_hidden_size': '${model_cfg.d_model}', '_target_': <class 'models.backbone.segformerx.SegFormerXFPN'>}, 'head': {'d_model': '${model_cfg.d_model}', 'nhead': '${model_cfg.nhead}', 'ff_dim': '${model_cfg.ff_dim}', 'num_query': 100, 'num_layers': '${model_cfg.num_layers_dec}', 'num_scales': 3, 'pooler_resolution': 32, '_target_': <class 'models.ms_temporal_detr.ms_temporal_detr.QueryBasedDecoder'>}, 'model_cfg': '${model_cfg}', '_target_': <class 'models.ms_temporal_detr.ms_temporal_detr.MultiScaleTemporalDetr'>}}
[2022-12-20 15:25:00](torchtext.vocab.vectors:169)INFO Loading vectors from /export/home2/kningtg/WORKSPACE/moment-retrieval/data-bin/cache/.glove/glove.6B.300d.txt.pt
[2022-12-20 15:25:01](torchtext.vocab.vectors:169)INFO Loading vectors from /export/home2/kningtg/WORKSPACE/moment-retrieval/data-bin/cache/.glove/glove.6B.300d.txt.pt
[2022-12-20 15:25:01](torchtext.vocab.vectors:169)INFO Loading vectors from /export/home2/kningtg/WORKSPACE/moment-retrieval/data-bin/cache/.glove/glove.6B.300d.txt.pt
[2022-12-20 15:25:04](root:141)INFO ==============START TRAINING=============
[2022-12-20 15:25:20](root:198)INFO Train Epoch   0 [61/306]	loss 3.250945	l1_loss 0.2561	iou_loss 0.0230	mask_loss 0.5488	enc_aux_loss 0.1319	dec_aux_loss 7.8640	grad_norm 3.1078	lr [0.0001]	batch_eta 0.2392s	mem 6679MB	
[2022-12-20 15:25:33](root:198)INFO Train Epoch   0 [122/306]	loss 3.094378	l1_loss 0.2537	iou_loss 0.0186	mask_loss 0.5413	enc_aux_loss 0.1315	dec_aux_loss 7.8594	grad_norm 1.5786	lr [0.0001]	batch_eta 0.1956s	mem 6679MB	
[2022-12-20 15:25:45](root:198)INFO Train Epoch   0 [183/306]	loss 3.119008	l1_loss 0.2560	iou_loss 0.0186	mask_loss 0.5304	enc_aux_loss 0.1310	dec_aux_loss 8.0542	grad_norm 1.7067	lr [0.0001]	batch_eta 0.1963s	mem 6679MB	
[2022-12-20 15:25:58](root:198)INFO Train Epoch   0 [244/306]	loss 3.159160	l1_loss 0.2593	iou_loss 0.0189	mask_loss 0.5379	enc_aux_loss 0.1291	dec_aux_loss 8.0904	grad_norm 1.7972	lr [0.0001]	batch_eta 0.1972s	mem 6720MB	
[2022-12-20 15:26:11](root:198)INFO Train Epoch   0 [305/306]	loss 3.160490	l1_loss 0.2615	iou_loss 0.0182	mask_loss 0.5527	enc_aux_loss 0.1286	dec_aux_loss 7.6736	grad_norm 1.7998	lr [0.0001]	batch_eta 0.1962s	mem 6720MB	
[2022-12-20 15:26:37](root:155)INFO Evaluated Val	R1@IoU=0.3 8.9720	R1@IoU=0.5 3.7196	R1@IoU=0.7 1.3526	R5@IoU=0.3 10.1217	R5@IoU=0.5 4.3057	R5@IoU=0.7 1.7583	loss 3.1625	eta 26.3293s
